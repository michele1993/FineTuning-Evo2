# Evo2 NVIDIA fine-tuning tutorial

To my knowledge, the only available script to fine-tune evo2 is provided via the **NVIDIA BioNeMo Framework** (i.e,  [here](https://docs.nvidia.com/bionemo-framework/latest/user-guide/examples/bionemo-evo2/fine-tuning-tutorial/)). Here, I describe how to install this framework on the CRG cluster, so that we can then run the evo2 fine-tune script on the cluster (and hopefully adapt it to our needs). 
This tutorial applies to any HPC facilites with [Apptainer](https://apptainer.org) installed.
I also include a step to step guidance on how to run the actual script (see Evo2 fine-tuning tutorial section below).

## Installation

We first need to set-up the **NVIDIA BioNeMo Framework** , which includes all the API (e.g, scripts) to fine-tune evo2.

### BioNeMo Framework

- a free-to-use collection of programming tools and packages offering access to optimized, pre-trained biomolecular models and workflows.

**Set-up**

Fortunately, the Bionemo framework is provided as a Docker container, including all the necessary dependencies. Although the CRG cluster does not have Docker, we can use this container via Apptainer (Singularity), which is installed in the cluster (see [here](https://developer.nvidia.com/blog/docker-compatibility-singularity-hpc/) for more info on how to run docker Bionemo containers in Apptainer/Singularity).

In order to access this (Bionemo framework) container, we need to perform the following steps: 

1. Create a **free** account on [NGC](https://ngc.nvidia.com/signin) (just insert your email address to create a new account if don't have one)

2. Log in & generate API KEY by going to **User** (top right corner where you email address is displayed) **> Setup > Generate API Key, then click + Generate API Key and Confirm**. Store the API Key in a secure location (we gonna need it)

3. Log in CRG cluster and then add the docker username (don't worry about this, it is autogenerated) and the API key that you generated in step 2. as environment variables. The easiest way to do this is to 
	add these variables to your `.bash_profile` file in the home directory, `$HOME` (i.e., where you login). 
	To do so, open your `~/.bash_profile` with your preferred editor (e.g., vim) and paste the following, (if you don't have a `.bash_profile` file in home dir, create one),
```
export NGC_API_KEY= GENERATED_API_KEY
export SINGULARITY_DOCKER_USERNAME='$oauthtoken'
export SINGULARITY_DOCKER_PASSWORD="$NGC_API_KEY"
```
where you **need to insert** the generated API Key of step 2 instead of `GENERATED_API_KEY` in the first line.

**IMPORTANT** To prevent Apptainer from running out of memory in your home directory, you should also set the following variables in your `.bash_profile`, ensuring Apptainer `cache` and  `tmp` are stored in the much bigger `no_backup` directory,
```
export APPTAINER_CACHEDIR="/no_backup/YOUR_GROUP_NAME/YOUR_USER_NAME"
export APPTAINER_TMPDIR="/no_backup/YOUR_GROUP_NAME/YOUR_USER_NAME"
```
where you should fill `/YOUR_GROUP_NAME/YOUR_USER_NAME` appropriately (**Note** if you don't have a `/no_backup` folder for your username send a ticket to IT to create one).

Next run,
```
source ~/.bash_profile
```

to load the changes (After this, if you run `echo $SINGULARITY_DOCKER_PASSWORD` your generated API KEY should appear).

**Note** if you don't want to have these variables in your `.bash_profile`, I recommend using [direnv](https://direnv.net/docs/installation.html) which you can easily install in the CRG cluster from binary without sudo privileges.

4. Now that we have set the correct variables, we can finally download the BioNemoFramework container by pulling this container with Apptainer (installed in the cluster). To do so, run the following,
```
apptainer pull docker://nvcr.io/nvidia/clara/bionemo-framework:2.5
```
This is going to take a while (i.e, 16GB), in my case it took roughly 40 min to complete. If this process completes correctly, you should have a `bionemo-framework_2.5.sif` file in your current directory.

5. In `bionemo-framework_2.5.sif`, we have the entire BioNeMo Framework inside a container that we can run in the CRG cluster with Apptainer, including  all the dependencies needed to run the NVIDIA fine-tune evo2 tutorial (and extend it to any custom dataset).

From here you can use this container as it suits you (no only for evo2 but for any BioNeMo model/functionality).Below I include the steps on how I reproduced the actual NVIDIA evo2 fine-tune [tutorial](https://docs.nvidia.com/bionemo-framework/latest/user-guide/examples/bionemo-evo2/fine-tuning-tutorial/) using this container.

## Evo2 tutorials

Now that we have access to the **NVIDIA BioNeMo Framework**, we can use it to any the NVIDIA evo2 tutorials.

We can do this by asking for an interactive job or by creating appropriate job scripts, asking for at least a GPU with 40GB GPU.

**From an interactive job**
Once, you are granted the interactive node, execute the following to run the container interactively (should be run from the directory where you stored the `bionemo-framework_2.5.sif` file),
```
apptainer shell --nv bionemo-framework_2.5.sif
```
This will open a shell from inside the container with access to all the Bionemo functionalities. 
Since we asked for an interactive node, we can run stuff directly from this "Apptainer" shell, which will be executed by the interactive node.
From inside here, you have access to all the scripts/functions used in the NVIDIA tutorials. Since I don't want to run a JupiterNotebook, I created corresponding python scripts to perform all the required operations (you can find these scripts in this repo).


### 1st Tutorial:fine-tuning evo2
([here](https://docs.nvidia.com/bionemo-framework/latest/user-guide/examples/bionemo-evo2/fine-tuning-tutorial/))

#### 1) Training Data
 Evo2 uses megatron style datasets with advanced support for randomly indexing into documents, and packing documents together into batches at scale.
 
**So** this step requires converting the required FASTA dataset to this format, through the following substeps,
1. Create a `.yaml` config file. For an example on how to do this in python, look at the `get_data.py` [script](https://github.com/michele1993/FineTuning-Evo2/blob/master/get_data.py) where we first download some fasta sequences and then create the `preprocess_config.yaml` file (as in the original NVIDIA tutorial). This is also where you specify top level train/validation/test splitting decisions. 

**Key** here you can specify any custom **fasta** dataset, by passing its path to the `datapaths` flag. The important thing is that you create an appropriate preprocess_config.yaml for the next (preprocessing) step

2. Call `preprocess_evo2` from the BioNeMo framework to generate the required dataset.
```bash
preprocess_evo2 --config preprocess_config.yaml
```

#### 2) Select desired checkpoint and convert to nemo2
Step 2 involves converting a desired evo2 model checkpoint available in savanna format to nemo2 format (i.e., format used by the BioNeMo framework).

This can be done by calling `evo2_convert_to_nemo2` script from the BioNeMo framework
**Crucially** Here we can specify the desired model checkpoint (i.e., any evo2 hugging face can be used).

```bash
evo2_convert_to_nemo2 --model-path hf://arcinstitute/savanna_evo2_{MODEL_SIZE}_base --model-size {MODEL_SIZE} --output-dir nemo2_evo2_{MODEL_SIZE}_8k
```
where `MODEL_SIZE` could be `1b`, `7b` or `40b`.

**IMPORTANT** should check or use if statement to make sure required model isn't already downloaded (e.g., in `.cache` dir).

#### 3) Config the training data
Create a config file for the created megratron dataset (for an example on how to do this, look at the `create_training_config.py` [script](https://github.com/michele1993/FineTuning-Evo2/blob/master/create_training_config.py)). This other config file must then be passed to `-d flag of `train_evo` script in the next step.


#### 4) Training
This is done via the `train_evo2` command, which takes several flags/options to specify a lot of things, from hyper-parameters (e.g., learning rate, batch size) to the number of devices, output directories etc. For a conrete example see the `train_evo.py` [scirpt](https://github.com/michele1993/FineTuning-Evo2/blob/master/train_evo.py).

**IMPORTANT** `train_evo2` takes `--fp8` flag to ensure FP8 is enabled during training in BioNemo, this is important if using the default 1b-evo2 (i.e., not robust to other precision).
However, I noticed using `--fp8` may give issue when running the `predict_evo2` script to get log likelihood.

**Parallelisation**
- We can specify the number of devices (i.e., GPUs), `--devices` as well as the number of nodes, `--num-nodes` as flags to `train_evo2`, allowing super easy parallelisation.

#### Key outputs
Below are the two most important outputs after running `train_evo2`, which will be stored in whater directory was passed to `--experiment-dir`.
**tensorboard output**: which can be found by running
```bash
find OUTPUT_DIR_NAME -name "events.out.tfevents*"
``` 
where `OUTPUT_DIR_NAME` depends on the directory passed to the `--experiment-dir` flag of `train_evo2`.

**SFT Model checkpoints**: The updated weights are available inside the directory that was passed to the `--experiment-dir` flag of `train_evo2`. These are conveniently named  as `'default--val_loss=...`,  reflecting the validation loss, epoch etc. There are multiple ones depending on the number of checkpoints that were carried out. The last one has a `-last` sufix. 

**Note** the `--ckpt-dir` flag of `train_evo2` is used to denote the directory from which the (base) model should be loaded for fine-tuning.

**Next** We can load this checkpoint and use it for inference (i.e., by passing its path to the `--ckpt-dir` flag of `infer_evo2`) and for loglikelihood prediction (i.e., by passing its path to the `--ckpt-dir` flag of `predict_evo2`).


**IMPORTANT** In the NVIDIA tutorial, they show the `1b` evo2 checkpoint is sensitive to `--fp8`, unlike the `7b` checkpoint (and `40b` ?). So you should only use the 1-billion checkpoint if you used FP8 enables (i.e., how it was trained)` or maybe find the newer corrected `1b` checkpoint if available. Alternatively, you need to use the 7-billion checkpoint, which does not suffer from this limitation and seems robust to FP8 being activated or not.

